{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGY7oRjeS9CyM8/lSiSHcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iranfromiran/nlp-assignments/blob/main/sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentiment analysis of revires of a product called Alexa on Amazon"
      ],
      "metadata": {
        "id": "qLExxmcwFLl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myDictionary ={}\n",
        "for roww in open('/content/AFINN-111.txt'):\n",
        "    word, score = roww.split('\\t')\n",
        "    myDictionary[word] = int(score)"
      ],
      "metadata": {
        "id": "O3dGOm6258ZP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import nltk.classify.util #calculates accuracy\n",
        "from nltk.classify import NaiveBayesClassifier #imports the classifier Naive Bayes\n",
        "from nltk.corpus import movie_reviews #imports movie reviews from nltk\n",
        "from nltk.corpus import stopwords #imports stopwords from nltk\n",
        "from nltk.corpus import wordnet #imports wordnet(lexical database for the english language) from nltk"
      ],
      "metadata": {
        "id": "bEuftRG3-otW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataSet_path = '/content/amazon_alexa.tsv'\n",
        "df = pd.read_csv(dataSet_path, sep='\\t')\n",
        "\n",
        "# Extract the 'verified_reviews' and 'feedback' columns cause thta's what we're gonna be using\n",
        "verified_reviews = df['verified_reviews']\n",
        "feedback = df['feedback']\n",
        "verified_reviews_words = df['verified_reviews'].str.split().explode()\n",
        "\n",
        "# Print the first few rows of each column to see if we did it right or not\n",
        "print(\"Verified Reviews:\")\n",
        "print(verified_reviews.head())\n",
        "print(\"\\nFeedback:\")\n",
        "print(feedback.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esuiDxmz-sMW",
        "outputId": "c26a9a64-82a1-4876-9a4b-1a5b4e6476b3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verified Reviews:\n",
            "0                                        Love my Echo!\n",
            "1                                            Loved it!\n",
            "2    Sometimes while playing a game, you can answer...\n",
            "3    I have had a lot of fun with this thing. My 4 ...\n",
            "4                                                Music\n",
            "Name: verified_reviews, dtype: object\n",
            "\n",
            "Feedback:\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: feedback, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#frequency distribution of words in reviews\n",
        "freq_dist = nltk.FreqDist(verified_reviews_words)\n",
        "freq_dist.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za3WwOKm-4y_",
        "outputId": "b2d68b19-523a-4757-8fff-649f45c5b7a9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 2879),\n",
              " ('I', 2835),\n",
              " ('to', 2772),\n",
              " ('and', 2169),\n",
              " ('it', 1673),\n",
              " ('a', 1458),\n",
              " ('my', 1278),\n",
              " ('is', 1188),\n",
              " ('for', 1014),\n",
              " ('with', 768)]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# clearing the input\n",
        "def create_word_features(words):\n",
        "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "    my_dict = dict([(word, True) for word in useful_words]) #so the words are not repeated\n",
        "    return my_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcYcFUui_Lqf",
        "outputId": "ef250943-b0d6-4763-a3d3-9c5c23f94679"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_reviews = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    review_text = row['verified_reviews']\n",
        "    feedback = row['feedback']  # 'feedback' column contains 0 or 1\n",
        "    # Check if the feedback is negative or 0\n",
        "    if feedback == 0:\n",
        "        # Tokenize the review text (split into words)\n",
        "        if isinstance(review_text, str):\n",
        "          words = review_text.split()\n",
        "\n",
        "        neg_reviews.append((create_word_features(words), \"negative\"))\n",
        "print(len(neg_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBiVCKIL_Q-6",
        "outputId": "fed2b54e-d406-4d8d-ea7c-8c4a17cd27e1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_reviews = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    review_text = row['verified_reviews']\n",
        "    feedback = row['feedback']  # 'feedback' column contains 0 or 1\n",
        "    # Check if the feedback is positive or 1\n",
        "    if feedback == 1:\n",
        "        # Tokenize the review text (split into words)\n",
        "        if isinstance(review_text, str):\n",
        "          words = review_text.split()\n",
        "\n",
        "        pos_reviews.append((create_word_features(words), \"positive\"))\n",
        "print(len(pos_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nOIiZYd_S66",
        "outputId": "8103e208-d575-4eb5-c4a5-5e023434ff9c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = neg_reviews[:192] + pos_reviews[:17170] #75% of the data\n",
        "test_set =  neg_reviews[192:] + pos_reviews[17170:]\n",
        "print(len(train_set),  len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVBLm0hE_ZEH",
        "outputId": "d9855d78-0b6c-413c-860b-11e61eee30f7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3085 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the NaiveBayesClassifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTlwednh_bDM",
        "outputId": "d6163f7b-fdfb-42e9-f5c3-5cd5ae8c7cdb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                  return = True           negati : positi =     49.3 : 1.0\n",
            "                     act = True           negati : positi =     45.0 : 1.0\n",
            "                 either. = True           negati : positi =     45.0 : 1.0\n",
            "                 Instead = True           negati : positi =     35.0 : 1.0\n",
            "                   Maybe = True           negati : positi =     35.0 : 1.0\n",
            "               defective = True           negati : positi =     35.0 : 1.0\n",
            "                  rarely = True           negati : positi =     35.0 : 1.0\n",
            "                  review = True           negati : positi =     35.0 : 1.0\n",
            "                 seconds = True           negati : positi =     35.0 : 1.0\n",
            "                 useless = True           negati : positi =     35.0 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
        "print(accuracy * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wma1h5e1_c0e",
        "outputId": "202a7edd-f9e4-49ce-b084-e015a6bfff1c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83.07692307692308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_1 = '''that's practical'''\n",
        "review_2 = '''it dosen't work for me and the packaging was bad'''\n",
        "review_3 = '''i can cook and listen to music and skip my playlist'''"
      ],
      "metadata": {
        "id": "OV8S4icW_e0u"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "words1 = word_tokenize(review_1)\n",
        "words1 = create_word_features(words1)\n",
        "print(classifier.classify(words1)\n",
        ")\n",
        "words2 = word_tokenize(review_2)\n",
        "words2 = create_word_features(words2)\n",
        "print(classifier.classify(words2))\n",
        "\n",
        "words3 = word_tokenize(review_3)\n",
        "words3 = create_word_features(words3)\n",
        "print(classifier.classify(words3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziWY0h2K_g5u",
        "outputId": "0bab520b-6bb2-4386-ee23-5dec49fc1433"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n",
            "negative\n",
            "positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}